'use strict';

/*
    The "AlgoliaProductsDeltaExport" job consists of two job steps:
    1. CatalogDeltaExport is a built-in SFCC job step which produces a standard-format SFCC delta export (but which lacks certain data needed by Algolia)
    2. algoliaSendDeltaExportProducts (this script) takes the output of CatalogDeltaExport, enriches it and sends it to Algolia.

    CatalogDeltaExport creates the following folder structure:

    path to the delta export zip:
        Impex / src / platform / outbox / <consumer> / <exportFile> / <seqNum>.zip

    the zip file's structure once extracted:
        <seqNum>.zip / <UUID> / catalogs / <catalogID> / catalog.xml

    consumer - default: "algolia" - one of the consumers supplied as the job step parameter "consumers" (comma-separated values) - a separate folder is created for each consumer supplied - CatalogDeltaExport supports multiple consumers, but this job step supports only one.
    exportFile - default: "productDeltaExport" - job step parameter - it's actually a folder, the CatalogDeltaExport system job step calls it a file, so we'll keep it like this for consistencies' sake
    seqNum - six-digit zero-padded sequential number, each run of the delta export job increments it by one - looks like this: 000001, 000002, etc.
    UUID - randomly generated by the delta export, looks like this: ebff9c4e-ac8c-4954-8303-8e68ec8b190d
    catalogID - one of the catalogIDs supplied as the job step parameter "catalogIDs" (comma-separated values) - a separate folder is created for each catalogID supplied (but only if there were changes to that catalog)
 */


/**
 * Second job step of the "AlgoliaProductsDeltaExport" job.
 * Takes the delta export created by the CatalogDeltaExport system job step,
 * enriches/transforms it and then sends it to Algolia for indexing.
 * @param {dw.util.HashMap} parameters Job step parameters - make sure to define the parameters for both job steps as job parameters, not step parameters so that they're shared across the job steps
 * @returns {dw.system.Status} Status
*/
function sendDeltaExportProducts(parameters) {

    var File = require('dw/io/File');
    var FileWriter = require('dw/io/FileWriter');
    var XMLStreamWriter = require('dw/io/XMLStreamWriter');
    var Status = require('dw/system/Status');

    var algoliaData = require('*/cartridge/scripts/algolia/lib/algoliaData');
    var algoliaConstants = require('*/cartridge/scripts/algolia/lib/algoliaConstants');
    var jobHelper = require('*/cartridge/scripts/algolia/helper/jobHelper');

    // initializing log data
    const updateLogType = 'LastProductDeltaSyncLog';
    var productLogData = algoliaData.getLogData(updateLogType);
    productLogData.processedDate = algoliaData.getLocalDateTime(new Date());
    productLogData.processedError = true;
    productLogData.processedErrorMessage = '';
    productLogData.processedRecords = 0;
    productLogData.processedToUpdateRecords = 0;

    var changedProducts = [];

    var success = false;


    // ----------------------------- PART 1: Extracting productIDs from the output of the Delta Export -----------------------------


    // checking if mandatory parameters are present
    if (empty(parameters.consumers) || empty(parameters.exportFile)) {
        let errorMessage = 'Mandatory job parameters missing!';
        jobHelper.logError(errorMessage);
        productLogData.processedErrorMessage = errorMessage;
        algoliaData.setLogData(updateLogType, productLogData);
        return new Status(Status.ERROR);
    }

    var paramConsumer = parameters.consumers.split(',')[0].trim(); // comma-separated values, but we only need one copy, so ignoring the rest
    var paramExportFile = parameters.exportFile; // it's actually a folder

    // creating working folder (same as the delta export output folder) - if there were no previous changes, the delta export job step won't create it
    var l0_deltaExportDir = new File(algoliaConstants.ALGOLIA_DELTA_EXPORT_BASE_FOLDER + paramConsumer + '/' + paramExportFile); // Impex/src/platform/outbox/algolia/productDeltaExport

    // return OK if the folder doesn't exist, this means that the CatalogDeltaExport job step finished OK but didn't have any output (there were no changes)
    if (!l0_deltaExportDir.exists()) {
        return new Status(Status.OK);
    }

    // list all the delta export zips in the folder
    var deltaExportZips = jobHelper.getDeltaExportZipList(l0_deltaExportDir);

    // if there are no files to process, there's no point in continuing
    if (empty(deltaExportZips)) {
        return new Status(Status.OK);
    }

    // creating empty temporary "_processing" dir
    var l1_processingDir = new File(l0_deltaExportDir, '_processing');
    if (l1_processingDir.exists()) {
        jobHelper.removeFolderRecursively(l1_processingDir);
    }
    l1_processingDir.mkdir();

    // creating "_completed" dir
    var l1_completedDir = new File(l0_deltaExportDir, '_completed');
    l1_completedDir.mkdir(); // creating "_completed" folder -- does no harm if already exists

    // process each export zip one by one
    deltaExportZips.forEach(function(filename) {
        var currentZipFile = new File(l0_deltaExportDir, filename); // 000001.zip, 000002.zip, etc.

        // this will create a structure like so: "l0_deltaExportDir/processing/000001.zip/ebff9c4e-ac8c-4954-8303-8e68ec8b190d/catalogs/apparel-catalog/catalog.xml"
        var l2_tempZipDir = new File(l1_processingDir, filename);
        if (l2_tempZipDir.mkdir()) { // mkdir() returns a success boolean
            currentZipFile.unzip(l2_tempZipDir);
        }

        // there's a folder with a UUID as a name one level down, we need to open that
        var l3_uuidDir = jobHelper.getFirstChildFolder(l2_tempZipDir); // processing/000001.zip/ebff9c4e-ac8c-4954-8303-8e68ec8b190d/

        // UUID-named folder has a folder called "catalogs" in it, open that
        var l4_catalogsDir = new File(l3_uuidDir, 'catalogs'); // processing/000001.zip/ebff9c4e-ac8c-4954-8303-8e68ec8b190d/catalogs/

        // getting child catalog folders, there can be more than one - folder name is the ID of the catalog
        var l5_catalogDirList = jobHelper.getChildFolders(l4_catalogsDir);

        // processing catalog.xml files in each
        l5_catalogDirList.forEach(function(l5_catalogDir) {

            var catalogFile = new File(l5_catalogDir, 'catalog.xml');

            // adding productsIDs from the XML to the list of changed productIDs
            // success contains the number of successfully read records or false if an error occurred
            success = jobHelper.updateChangedProductsObjectFromXML(catalogFile, changedProducts);

            if (success) {
                // success contains the number of successfully read records
                productLogData.processedRecords += success;

                // deleting successfully processed files and their parent folders
                success = catalogFile.remove() && l5_catalogDir.remove();
            } else {
                // abort if error reading from any of the delta export zips
                let errorMessage = 'Error reading from file: ' + filename;
                jobHelper.logError(errorMessage);
                productLogData.processedErrorMessage = errorMessage;
                algoliaData.setLogData(updateLogType, productLogData);
                return new Status(Status.ERROR);
            }
        });

        // cleanup: removing unzipped files that are already processed, along with their parent dirs
        // this removes `l4_catalogsDir`, `version.txt` from `l3_uuidDir`, `l3_uuidDir` and `l2_tempZipDir` itself
        jobHelper.removeFolderRecursively(l2_tempZipDir);
    });

    // writing number of records read from the SFCC delta zips
    jobHelper.logInfo(productLogData.processedRecords + ' records read from SFCC delta zips');


    // cleanup - removing "_processing" dir
    jobHelper.removeFolderRecursively(l1_processingDir);


    // ----------------------------- PART 2: Retrieving and enriching the products, writing them to XML -----------------------------


    // open Delta XML file to write
    var updateFile, updateFileWriter, updateXmlWriter;
    try {
        // <siteID>_product_update.xml
        updateFile = new File(l0_deltaExportDir, algoliaConstants.ALGOLIA_DELTA_EXPORT_UPDATE_FILE_NAME);

        // if there's already an update XML from a previous unsuccessful attempt, remove it
        if (updateFile.exists()) {
            updateFile.remove();
        }

        // creating file, writing start elements
        updateFileWriter = new FileWriter(updateFile, 'UTF-8');
        updateXmlWriter = new XMLStreamWriter(updateFileWriter);
        updateXmlWriter.writeStartDocument();
        updateXmlWriter.writeStartElement('products');

    } catch (error) {
        let errorMessage = 'Error opening delta XML for writing';
        jobHelper.logFileError(updateFile.fullPath, errorMessage, error);
        productLogData.processedErrorMessage = errorMessage;
        algoliaData.setLogData(updateLogType, productLogData);
        return new Status(Status.ERROR);
    }

    // retrieving products from database and enriching them
    for (var currentObject of changedProducts) {
        for (var productID in currentObject) {

            var isAvailable = currentObject[productID];

            var productUpdateObj;

            if (isAvailable) { // <productID>: true - product was either added or modified

                var productFilter = require('*/cartridge/scripts/algolia/filters/productFilter');
                var AlgoliaProduct = require('*/cartridge/scripts/algolia/model/algoliaProduct');

                var ProductMgr = require('dw/catalog/ProductMgr');

                var product = ProductMgr.getProduct(productID); // get product from database, send remove request to Algolia if null

                if (!empty(product)) {
                    var algoliaProduct = new AlgoliaProduct(product);
                    productUpdateObj = new jobHelper.UpdateProductModel(algoliaProduct);

                } else { // the data from the delta export about this product is stale, product can no longer be found in the database -- send a remove request
                    productUpdateObj = new jobHelper.DeleteProductModel(productID);
                }

            } else { // <proudctID>: false - product is to be deleted
                productUpdateObj = new DeleteProductModel(productID);
            }

            // writing product data to file
            if (productUpdateObj) {
                try {
                    jobHelper.writeObjectToXMLStream(updateXmlWriter, productUpdateObj);
                } catch (error) {
                    let errorMessage = 'Error writing to update XML file';
                    jobHelper.logFileError(updateFile.fullPath, errorMessage, error);

                    productLogData.processedErrorMessage = errorMessage;
                    algoliaData.setLogData(updateLogType, productLogData);

                    updateFileWriter.close();
                    updateXmlWriter.close();
                    return new Status(Status.ERROR);
                }
                productLogData.processedToUpdateRecords++;
            }
        }
    }

    // closing XML update file
    updateXmlWriter.writeEndElement();
    updateXmlWriter.writeEndDocument();
    updateXmlWriter.close();
    updateFileWriter.close();

    // writing number of records written to XML file
    jobHelper.logFileInfo(updateFile.fullPath, productLogData.processedToUpdateRecords + ' records written to update XML file');

    // writing number of processed records to update log
    productLogData.processedDate = algoliaData.getLocalDateTime(new Date());
    productLogData.processedError = false;
    productLogData.processedErrorMessage = '';
    algoliaData.setLogData(updateLogType, productLogData);


    // ----------------------------- PART 3: Sending the contents of the XML to Algolia -----------------------------


    var status = new Status(Status.ERROR);

    var sendDelta = require('*/cartridge/scripts/algolia/helper/sendDelta');
    var deltaIterator = require('*/cartridge/scripts/algolia/helper/deltaIterator');

    // opening delta XML and sending contents to Algolia
    var deltaList = deltaIterator.create(updateFile.fullPath, 'product');
    if (!empty(deltaList)) {
        status = sendDelta(deltaList, updateLogType, parameters); // returns Status.OK if all is well
    }

    if (status.error) {
        let errorMessage = status.details.errorMessage ? status.details.errorMessage : 'Error sending delta. See the logs for details.';
        jobHelper.logError(errorMessage);
        productLogData = algoliaData.getLogData(updateLogType); // need to get it again since sendDelta has updated the file, the in-memory one is out of date
        productLogData.processedErrorMessage = errorMessage;
        algoliaData.setLogData(updateLogType, productLogData);
        return new Status(Status.ERROR);
    }

    // delta successfully sent, remove update file
    updateFile.remove();

    // cleanup: after the products have successfully been sent, move the delta zips from which the productIDs have successfully been extracted and the corresponding products sent to "_completed"
    deltaExportZips.forEach(function(filename) {
        var currentZipFile = new File(l0_deltaExportDir, filename); // 000001.zip, 000002.zip, etc.
        var targetZipFile = new File(l1_completedDir, currentZipFile.getName());
        jobHelper.moveFile(currentZipFile, targetZipFile);

        var currentMetaFile = new File(l0_deltaExportDir, filename.replace('.zip', '.meta')); // each .zip has a corresponding .meta file as well, we'll need to delete these later
        var targetMetaFile = new File(l1_completedDir, currentMetaFile.getName());
        jobHelper.moveFile(currentMetaFile, targetMetaFile);
    });

    return status;
}

module.exports.sendDeltaExportProducts = sendDeltaExportProducts;
